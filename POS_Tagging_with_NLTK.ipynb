{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1a9c7b-486f-46e1-82b8-3bdff8febeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import UnigramTagger, BigramTagger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e94c6b6-ba4c-4762-b1b2-1d2c30c0f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ahmed\\anaconda3\\envs\\neuralnetwork\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\ahmed\\anaconda3\\envs\\neuralnetwork\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ahmed\\anaconda3\\envs\\neuralnetwork\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')      # For tokenizing text into words\n",
    "nltk.download('treebank')   # For accessing the Treebank tagged corpus\n",
    "nltk.download('averaged_perceptron_tagger')  # For POS tagging models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bf20d7-98ad-4f8f-a593-a53c5bed9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a portion of the treebank corpus for training and testing\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "test_sents = treebank.tagged_sents()[3000:3500]\n",
    "\n",
    "# Alternatively, we can also tokenize text to make use of it later\n",
    "example_sentence = \"This is an example sentence.\"\n",
    "tokenized_sentence = word_tokenize(example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8ecc5e-dad2-4d05-b9fd-c2562944df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "\n",
    "# Create a DefaultTagger for unseen words (e.g., tag everything as 'NN' - noun)\n",
    "default_tagger = DefaultTagger('NN')\n",
    "\n",
    "# Train Unigram and Bigram taggers with a backoff to the default tagger\n",
    "unigram_tagger = UnigramTagger(train_sents, backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(train_sents, backoff=unigram_tagger)\n",
    "\n",
    "# Combining the taggers (if needed)\n",
    "combined_tagger = BigramTagger(train_sents, backoff=unigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe6b073-dd63-4b99-bc71-b30d25aaf772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NLTK', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('great', 'JJ'), ('toolkit', 'NN'), ('for', 'IN'), ('NLP', 'NN'), ('tasks.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Test the POS tagger on a tokenized sentence\n",
    "test_sentence = \"NLTK is a great toolkit for NLP tasks.\".split()\n",
    "tagged_sentence = combined_tagger.tag(test_sentence)\n",
    "print(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16223889-7b74-4ece-977a-1d2ec7d5b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger Accuracy: 88.31%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tagger on the test set\n",
    "accuracy = combined_tagger.accuracy(test_sents)\n",
    "print(f\"Tagger Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
